Error	Taxonomy (cause)	Taxonomy (MC)	mirage-error	Hide	AUDIT NOTES	Lint	implemented	Citations	Notes	Detection Technique	Taxonomy Order	 	Initial Taxonomy zone	Group			LOOKUP	VALUE
Forgotten Population/Missing Dataset (checked)	Curation	Curation	We expect that datasets fully cover or describe phenomena of interest. However, structural, political, and societal biases can result in over- or under-sampling of populations or problems of importance. This mismatch in coverage can hide crucial concerns about the possible scope of our analyses.			Not possible	No	\cite{missingdatasets, dignazio2019draft}										
Missing/Repeated Records (checked)	Curation	Curation, Wrangling	We often assume that we have one and only one entry for each datum. However, errors in data entry or integration can result in missing or repeated values that may result in inaccurate aggregates or groupings (see \figref{fig:misspelling}).		Metamorphic testing is possible: "remove all copies" could possibly check types	Direct possible	No	\cite{kim2003taxonomy} 		Data, Spec	1	Aggregates might become inaccurate, impeding all comparisons	Totally Invisible	Aggregation issues			Curation	1
Outliers (checked)	Curation	Curation, Wrangling	Many forms of analysis assume data have similar magnitudes and were generated by similar processes. Outliers, whether in the form of erroneous or unexpectedly extreme values, can greatly impact aggregation and discredit the assumptions behind many statistical tests and summaries.					\cite{kim2003taxonomy} 	Can affect ability to read aggregate visualization accurately	Data, Spec	1	Aggregates might become inaccurate, impeding all comparisons	Totally Invisible	Aggregation issues			Wrangling	2
Dubious Data	Curation			TRUE					Cairo's new book	Data	1		Statistical Malpractice					
Insufficient Data	Curation		Data may be cherry picked, as a non-representative sample, or may not be robust enough to accurately backup the rendered claim in the visualization.	TRUE					Cairo's new book	Data	1		Statistical Malpractice					
Spelling Mistakes (checked)	Curation	Curation, Wrangling	Columns of strings are often interpreted as categorical data for the purposes of aggregation. If interpreted in this way, typos or inconsistent spelling and capitalization can create spurious categories, or remove important data from aggregate queries.		Metamorphic test: merge all categorical fields within a certain hemming distance, expect that to not produce changes			\cite{wang2019uni}		Data	1							
Uniqueness Constraint Failure	Curation		Marks assumed to represent single values might represent several (which may then be further skewed by aggregates like SUM).	TRUE				\cite{wang2019uni}	assumed singular values may be aggregated. Example: making a line chart of year has data from 1.5 years. Users assumes each mark indicates ONE measurement, when in fact their might be several	Data	1							
Unidentified Functional Dependencies	Curation	Curation	Visualization might show a strong relationship between variables, when in fact that relationship is part of the data composition (eg A+B = C, plot A vs C)	LONG	Having trouble with this one. I can't seem to get through it without either a length prose example ("assume customers only received a discount if they sold a widget..."), or by referencing a figure. Given that the mirages here are a subtle, and might be picked up as a superset of simpson's paradox or latent variables or something else, maybe this one gets skipped?			\cite{wang2019uni}	Uni-Detect: A Unified Approach to Automated Error Detection in Tables	Data	1							
Drill-down Bias (checked)	Curation	Wrangling, Reading?	We assume that the order in which we investigate our data should not impact our conclusions. However, by filtering on less explanatory or relevant variables first, the full scope of the impact of later variables can be hidden. This results in insights that address only small parts of the data, when they might be true of the larger whole.		Could conceivable lint if you've got a bunch of filters applied by just applying them in a random order and seeing how fragile the bar heigh order is? If it's robust you'd expect it to be only when the last filter is applied, no matter the order. Seems contrived, thoughl you could also just do the direct lint in the paper.			\cite{lee2019avoiding}		Data, Spec	1		Statistical Malpractice					
Geopolitical Boundaries in Question	Curation	Curation		LONG	Is french guiana counted as part of france?	Direct	No											
Differing Number of Records by Group (checked)	Wrangling	Wrangling	Certain summary statistics, including aggregates, are sensitive to sample size. However, the number of records aggregated into a single mark can very dramatically. This mismatch can mask this sensitivity and problematize per-mark comparisons; when combined with differing levels of aggregation, it can result in counter-intuitive results such as Simpson's Paradox.		Lives in wrangling bc it's a result of the aggregation decision	Direct, MT	Yes	\cite{guo2017you}	A mismatch in row cardinality (world indicators example)	Data, Spec	2	Aggregate may be perceived as having a common cardinality	Totally Invisible	Aggregation issues				
Simpson's Paradox	Wrangling	Wrangling	An observed trends reverses when the aggregation level changes.  Trends observed across groups at one level of aggregation may change or even reverse when the aggregation level changes, due to differing sizes of groups. This can result in counter-intuitive or erroneous insights if 	TRUE	Lots of overlap with the "Differing Numbers of Records by Group" in that we describe both as being where differing group sizes combined with aggregation = badness. Might make sense to merge diff. #s of records with this one?			\cite{guo2017you}		Data, Spec	2	Observed trend reverses when aggregation changes	Totally Invisible	Aggregation issues				
Cherry Picking	Wrangling	Wrangling	Filtering down to an uncharacteristic subset offers an incorrect distribution.		Some overlap here with the Drill Down Bias			\cite{few2019loom}	e.g. the chart filters out to only a tiny subset of data where something is true. data loom: law of small numbers (cherry picking, bias sample fallacy)	Data, Spec	2		Totally Invisible					
Dominating Outlier Wrecks Scale	Wrangling	Wrangling, Visualizing?	The magnitude of a real trend might be nullified or made invisible, causing the reader to miss a real data trend. 	LONG	Should merge with the other scale issues IMO			\cite{kindlmann2014algebraic}	SLIGHTLY UNSURE ABOUT CLASSIFICATION	Data, Spec	2	Real trend is made invisible						
Spurious Correlation	Wrangling	Wrangling	Correlation is not robust to slight changes in the data, which may give the impression of a non-extant correlation.	TRUE					Correlation is not robust to slight changes in the data	Data	2		Statistical Malpractice					
Higher Noise than Effect Size	Wrangling	Curation, Wrangling	A high variability or noise in can mask the real information being presented, causing readers to identify non-existent trends.					WICKAM LINEUPS?		Data	2	Irrelevant conclusions could be made	Statistical Malpractice					
P-Hacking	Wrangling	Wrangling	Spurious difference (due to p-hacking, say. or just un-communicated sampling variability) can give the impression of non-extant correlation.					\cite{pu2018garden}	Spurious difference (due to p-hacking, say. or just un-communicated sampling variability)	Data	2	Gives the impression of an non-extant correlation	Statistical Malpractice					
Outliers Combined with Wrong Aggregation Type	Wrangling	Wrangling	Using extremal aggregates (such as min/max) will likely cause misinterpretation of bars as readers tend to assume bars show sums. (I THINK THIS WHAT WITHIN BAR SAYS)		I'm getting a mismatch here between title and description			\cite{newman2012bar}		Data, Spec, Render	2							
Aggregates Mask Second Order Statistics	Wrangling	Wrangling	Second order statistics often carry critical information about the variance or distribution, which is masked through simple central tendencies. 	LONG				\cite{wall2017warning, few2019loom, matejka2017same, anscombe1973graphs}	dinosaurus box plot, anscombe's quartet, variation blindness (the median isn't the message - gould)	Data, Spec, Render	2	Two things may appear to be equal when in fact their distributions are fundamentally different	Totally Invisible	Aggregation issues				
Additional Loom Statistical errors	Wrangling			TRUE				\cite{few2019loom}	data loom: law of small numbers (cherry picking, bias sample fallacy), insensitivity to small sample size, base rate fallacy, hot hand fallacy, appeal to coincidence, regression fallacy, variation blindness (the median isn't the message - gould)		2							
Insensitivity to Small Sample Size	Wrangling	Reading		LONG	To me this is a meatspace issue; it's not "caused" by the small sample size, it's caused by people not making the appropriate inferences about the effects of sample size. I'll check how the readings in the cite list use this term.			\cite{few2019loom}	data loom									
Hot Hand Fallacy	Wrangling	Reading		LONG				\cite{few2019loom}	data loom									
Appeal to Coincidence	Wrangling	Reading		LONG				\cite{few2019loom}	data loom									
Regression Fallacy	Wrangling	Reading		LONG				\cite{few2019loom}	data loom									
Inappropriate Use of Mean	Wrangling	Wrangling	Mean comparisons between non-normal and normal distribution will be skewed, rendering possibly inaccurate comparisons between groups.	TRUE	Already covered in "Aggregates Mask Second Order Statistics"			\cite{few2019loom}	Data loom (mean is design for normal distributions)	Data, spec	2							
Confusing Imputation	Wrangling	Wrangling	Imputation that generates zeroes rather removing rows can radically alter aggregates.					\cite{song2018s}	"Where's My Data?" 		2							
Sampling Rate Errors 	Wrangling	Curating, Wrangling	An apparent trend may be an artifact of the sampling rate rather than the data.					\cite{kindlmann2014algebraic}			2	Apparent trend will be the aliases rather than the signal						
Data Classes Distinctions Ignored	Wrangling	Wrangling	Multiple distinct data classes presented as the same can cause errors in the inference of trends.					\cite{anand2015automatic}	Automatic Selection of Partitioning Variables for Small Multiple Displays,related to simpson's paradox	Data, spec	2							
Non-sequitur Visualizations (checked)	Visualization	Visualization	Readers expect graphics that appear to be charts to be a mapping between data and image. Visualizations being used as decoration (in which the marks are not related to data) present non-information that might be mistaken for real information.			MT	yes	\cite{correll2017black}										
Banking to 45 Failure	Visualization	Visualization	Not using an appropriate aspect ratio can cause trends to be hallucinated in otherwise trend-free data.					\cite{heer2006multi}	HEER PAPER. Mirages can be perceptual in nature, but are driven by a decision somewhere in the analytics pipeline. The knob that controls this mirage is charts dimensions	Data, spec, render	3	Trend can appear from flat data or vice-versa						
Misunderstand Area as Quantity (checked)	Visualization	Visualization	The use of area encoded marks assumes readers will be able to visually compare those areas. Area encoded marks are often misunderstood as encoding length which can cause ambiguity about interpretation of magnitude.					\cite{pandey2015deceptive, correll2017black}	e.g. “the incredible shrinking doctor”	Spec	3		Visible Only With Effort	Bad Quant Scales				
Non-discriminable Colors (checked)	Visualization	Visualization	The use of color as a data-encoding channel presumes the perceptual discriminability of colors. Poorly chosen color palettes, especially when marks are small or cluttered (cite), can result in ambiguity about which marks belong to which color classes.					JND CITATION?		Spec	3	Reader mistakes one group for another	Visible Only With Effort	Bad color scale				
Unconventional Direction of Time 	Visualization		Readers expect time to progress in the same direction as their language, reversing convention can cause reversed interpretation.	TRUE				\cite{correll2017black}	Readers tend to think of time as flowing in the same direction as their language (CITATION), eg western language speakers tend to think of it as moving from left to right while REST OF EXAMPLE.	Spec, Data, Render	3							
Overplotting (checked)	Visualization		Apparently singular marks usually represent a single value or aggregate. Yet overlapping opaque marks are read as a single mark which can cause severe misterpretations of the distribution or impose an incorrect aggregation, as in \figref{fig:opacity-permute}.			MT	YES	CITATION PLZ		Data, Spec, Render	3		Totally Invisible	Rendering Issues				
Singularities (checked)	Visualization	Visualization	Some mark types, such as line series, are vulnerable to all of their data converging to a single point in visual space (as might occur in a parallel coordinates chart). Without graphical intervention readers can face an ambiguity in discerning paths in visual space.			MT		\cite{kindlmann2014algebraic}	parallel coordinates AVD example	Data, Render	3		Totally Invisible	Rendering Issues				
Improper Layering / Overplotting	Visualization	Visualization	Overplotting can cause an non-existent trend to emerge due to the draw order. 	TRUE	AM: Overplotting is it's own thing			\cite{kindlmann2014algebraic}	taxi AVD example	Data, Render	3		Totally Invisible	Rendering Issues				
Latent Variables Missing	Visualization	Wrangling, Visualization?	??????? never been sure what this means? 							Spec	3		Totally Invisible					
Wrong/Missing Aggregation	Visualization	Wrangling	AM: I THINK THIS IS A THING BUT WE DONT REALLY HAVE A DESCRIPTION OF IT							Spec, Render	3		Totally Invisible					
Flipped Axes (checked)	Visualization	Visualization	There are conventional expections for the meaning of axis directions (e.g., time as left to right). When a design ignores those expectations, it can result in a perceived inversion of the trend. 		Error occurs in reading, but "mistake" is in the spec. Superset of line "Unconventional Dirction of Time.	direct		\cite{pandey2015deceptive, correll2017black}	Black hat, panday, Variables on Scatter Plots Look More Highly Correlated When the Scales are Increased	Spec	3	Trend understood to be opposite	Visible Only With Effort	Bad Quant Scales				
Scale Extents Larger than Range of the Data	Visualization	Visualization	Differences compressed and visual variability is removed.					\cite{cleveland1982variables}	Variables on Scatter Plots Look More Highly Correlated When the Scales are Increased	Spec	3		Visible Only With Effort	Bad Quant Scales				
Non-linear Scales	Visualization	Visualization	Can cause readers to inaccurately correlate variables and cluster values.					\cite{pandey2015deceptive}		Spec	3		Visible Only With Effort	Bad Quant Scales				
Truncated/Expanded Axes	Visualization	Visualization	Axes constructed in an unintuitive manner may hide variance or cause errors in sorting marks or characterizing the distribution.  The choice of where to place the visual zero line of an axis presumes that XXX. Selections of overly truncated or expanded axes can cause exagerated effect sizes, which can lead to erroreous judgements (such as in XXX). 					\cite{pandey2015deceptive, correll2017black, cleveland1982variables, ritchie2019lie, correll2019truncating}	Variables on Scatter Plots Look More Highly Correlated When the Scales are Increased, Black hat, panday	Spec, Data	3	Can cause sorting errors and errors in characterizing distribution						
Colors Binned Unevenly	Visualization	Visualization	Irregular or uintutive binning may negatively affect interpretation of bin meaning.	TRUE	AM: I'm not actually sure this is a problem?			CITATION?		Spec	3		Visible Only With Effort	Bad color scale				
Base Rate Masquerading as Data (checked)	Visualization	Wrangling, Visualization	Visualizations comparing rates are often assumed show the relative rate, rather than the absolute rate. Yet, many displays give prominence to these absolute or base rates (such as population in choropleth maps) rather than encoded variable, causing the reader to understand this base rate as the data rate. 		Metamorphic test: swap the input data for data that only shows the base rate, if nothing sufficently changes, then visualization isn't showing the real trend.	MT	No	\cite{correll2016surprise}	Surprise Maps	Spec	3		Visible Only With Effort	Bad color scale				
Inappropriate Semantic Color Scale (checked)	Visualization	Visualization	Data-encoded colors can collide with semantically meaningful colors, such as green on a map indicating a forest. This collision can cause readers to mistake the rendered data for associated with that color-connection.			Direct / Not possible	No	CITATION?	Green or blue map regions can lead the reader to believe that those regions posses semantically meaningful trends (forest/ocean respectively). CITATION NEEDED, maybe Selecting Semantically‐Resonant Colors for Data Visualization	Spec?	3			Bad color scale				
Within-bar-bias	Visualization	Visualization	Bar charts that have variability are frequently misunderstood.					\cite{newman2012bar}	Bar graphs depicting averages are perceptually misinterpreted: The within-the-bar bias	Spec	3	Readers misunderstand variability 	Visible Only With Effort	Rhetorical Nudges				
Highlight/Downplaying Outliers	Visualization	Visualization	Over highlighting outliers can mask important data features, however so can ignoring them.					CITATION?		Spec	3		Visible Only With Effort	Rhetorical Nudges				
Clipped Outliers (checked)	Visualization	Visualization	Charts are often assumed to show the full extent of their input data. A chosen domain might exclude meaningful outliers, causing some trends in the data to be invisible to the reader.		This might be subsumed by cherry picking?	Direct	No		specified domain removes significant outliers, may be the same as cherry picking	Data, Spec	3							
Continuous Marks for Nominal Quantities (checked)	Visualization	Visualization	Convetionally readers assume lines indicate continuous quantities and bars indicate discrete quanties. Breaking from this convention, for instance using lines for nominal measures, may cause readers to hallucinate non-existant trends based on ordering. 					\cite{mcnuttlinting, zacks1999bars}	Eg Line chart across nominal data. Citation VisLint, possibly also http://people.cs.uchicago.edu/~glk/class/datavis/lit/#Zacks-BarsAndLines-1999	Data, Spec	3		Charting malfeasance	Expressiveness mismatches				
Using Ordinal Measures as (Ratio/Interval) Measures	Visualization	Visualization	Related to "area/length mismatches" a mark might be encoded as big/medium/small which readers might then read as quantitative.					\cite{stevens1946theory, few2019loom}	Stevens, also data loom as "conflating rankings with measure of worth"	Data, spec	3							
V-Hacking	Visualization		Visualization includes arbitrary choices made by the designer that causes reader to hallucinate un-meaningful inferences. The modifiable areal unit problem is an example of this problem.	TRUE	AM: I knocked this one out because we coin the term and we don't describe it. It seems like it would need a more serious description than an entry in a table.			\cite{fotheringham1991modifiable, kindlmann2014algebraic}		Spec, Render	3	Purported insight not robust to minor changes	Charting malfeasance					
Modifiable Areal Unit Problem (checked)	Visualization		Spatial aggregates are often assumed as presenting their data without bias, yet they are highly dependent on the shapes of the bins defining those aggregates. This can cause readers to misunderstand the trends present in the data.		Metamorphic testing stratagey: count the fraction of number of bins showing each of a collection of data classes (say high/medium/low incidince of cancer), change the bin shape randomly a bunch of time, count again, compare rates.   I keep going back and forth on whther or not this should be in?	Direct, MT	No	\cite{fotheringham1991modifiable, kindlmann2014algebraic}	If you dont like modifiable areal unit being baked into v-hacking....									
Charting Parameter Masking Data Error	Visualization	Visualization	Non-data parameter can mask a critical data error, such as a histogram binning hiding a missing value.		Metamorphic test: change the number of bins check for significant changes to the bin character. More concrete: use DTW to compare bar order. KL DIVERGENCE?	MT	No	\cite{correll2018looks}	Over/under smoothed KDE, Over/under binned histogram. Looks good to me	Data, Spec, Render	3		Charting malfeasance					
Poorly Designed Charts	Visualization			TRUE					Cairo's new book	Spec	3		Charting malfeasance					
Concealed Uncertainty	Visualization	Visualization, Wrangling? (or maybe even Curating?) Issues of not bothering to even measure the uncertainty versus measuring it but not visualizing it	Charts that don't indicate that they contain uncertainty risk giving a false impression as well a possible extreme mistrust of the data if the reader realizes the information hasn't been presented clearly. 					\cite{song2018s, few2019loom, mayrTrust2019, sacha2015role}	Cairo's new book, Slightly different than missing records, following "Where's My Data?" visualizations should represent their missing data in some way. Maybe can point to "The Role of Uncertainty, Awareness, and Trust in Visual Analytics"	Data, Spec, Render	3		Charting malfeasance					
Charts with Misleading Patterns	Visualization			TRUE					Cairo's new book, black hat	Spec, Render	3		Charting malfeasance					
Sole Reliance on Measure of Central Tendency	Visualization	Wrangling	Second order statistics often carry critical information about the variance or distribution, which is masked through simple central tendencies. 					\cite{wall2017warning, few2019loom, matejka2017same, anscombe1973graphs}	Src: data loom. Could be tested by executing datasarus style data manipulation: keep an invariant the same and rotate the data via optimization	Data, render	3	Second order statistics carry more critical information or variance 						
Trend in Dual Y-Axis Charts are Arbitrary (checked)	Visualization	Visualization	Multiple line series appearing on a common axis are often read as being related through an objective scaling. Yet, when y-axes are superimposed the relative selection of scaling is arbitrary, which can cause readers to misunderstand the magnitudes of relative trends.			Direct	No	\cite{KindlmannAlgebraicVisPedagogyPDV2016, cairo2015graphics}	Cairo (poorly designed charts), can also point to that datawrapper blog post									
Uncorrelated Data Decorated with Best Fit Line (checked)	Visualization	Visualization	We expect lines of best-fit to accurately represent data trends. Yet, if uncorrelated data is presented alongside a mark conventionally understood to indicate a trend, then a reader may falsely understand those variables as being correlated.  						Uncorrelated data decorated with line of best fit. This arises from that line of best fit shown by that psych speaker			Uncareful reader might not investigate if the line of best fit actually matches with anything						
Staircasing	Visualization	Visualization, Wrangling	A trend on a noisy channel may appear to reverse because of the domain selection. MAYBE A SUBSET OF CHERRY PICKING?					IS THIS A KNOWN THING	https://twitter.com/NASAClimate/status/1154503255486955520  setting domain to a small subrange, particularly on a line chart, this might also be a subcase of cherry picking?		3	A trend on a noisy channel may appear to reverse because of the domain selection						
Nominal Choropleth Conflates Color Area with Classed Statistic	Visualization	Visualization	Conflating class coloring and area can give a misinterpretation of base rate, as is often this case in American presidential election maps. 					\cite{gastner2005maps} CHOROPLETH CITATION?										
Presentation Masks Information	Visualization	Visualization	The choice of graphical rendering may obscure data found in similar encodings. For instance, some graph layouts present their data clearly while others more closely resemble hairballs.					\cite{hofmann2012graphical} GRAPH CITATION										
Reification (fallacy) / mistaking the map for the territory	Comprehension	Reading		LONG				CITATION PLZ	https://en.wikipedia.org/wiki/Reification_(fallacy)									
Incorrectly Assumed High Quality Data/ Completeness bias	Comprehension	Reading	Trusting untrustworthy data cause readers to make incorrect conclusions about the information presented in a visualization.					\cite{mayrTrust2019, sacha2015role}	The Role of Uncertainty, Awareness, and Trust in Visual Analytics, trust in information visualization	Data	4	Trusting untrustworthy data can lead to missing upstream errors (such as falsey data)	Visible Only With Effort	Data quality errors			Visualization	3
Unwarranted causal implications	Comprehension	Reading	Correlated data misunderstood (based on visual encoding) as being causally related.					\cite{xiong2019illusion, few2019loom}										
Multiple Comparisons Problem	Comprehension	Reading, Wrangling?	Too many iterative comparisons has high probability of generating a configuration that offers a false comparison.					\cite{pu2018garden, zgraggen2018investigating}	Garden of forking paths, Zerdraggen. Possibly not relevant as we've constrained ourselves to presentational VA.	???	4	False inference from too many iterative comparisons	Statistical Malpractice				Comprehension	4
Not Accounting for Bias	Comprehension	Reading	Not addressing bias in the visual analytics process can lead analysts towards false conclusions.					\cite{wall2017warning}	Ala "bias may occur"	??	4							
Assuming View-from-Nowhere	Comprehension	Reading	The reader might inaccurately trust a visualization that doesn't present its origins.					\cite{dignazio2019draft, d2016feminist}	maybe same as not accounting for bias			Falsely trust visualizations that have a bias						
Causal Errors: Post hoc ergo propter hoc	Comprehension			TRUE				\cite{few2019loom}		??	4							
Causal Errors: Unit Bias	Comprehension			TRUE				\cite{few2019loom}		??	4							
Causal Errors: Outcome Bias	Comprehension			TRUE				\cite{few2019loom}		??	4							
Over-emphasizing Data-ink Minimalism	Comprehension	Visualization	Chart might not actually get read, minimalist charts are easier to ignore full message might get lost	TRUE		Not possible	no	\cite{bateman2010useful}	Data humanism/feminism: extremely minimalist data visualizations aren't memorable (MONSTER CITATION) or as emotionally impactful as illustrative ones (Data fem) . Visual Difficulties also might be of note here	??	4							
Confirmation Bias	Comprehension	Reading	Reader may see trend where one doesn't exist.					\cite{valdez2017framework, few2019loom}	Data loom	??	4							
Familiarity Errors: availability heuristic	Comprehension	Reading, Wrangling?	Falsely extrapolate meaning from data based on completionist set of data.	LONG				\cite{few2019loom}	Data loom	??	4	Falsely extrapolate meaning from data based on completionist set of data.						
Familiarity Errors: status quo bias	Comprehension			LONG				\cite{few2019loom}	Data loom	??	4							
Default Effect	Comprehension		The default settings of visualizations can have an outsized impact on the resulting design, potentially hiding value of interest but  also potentially guiding a user toward best practices.	TRUE	AM: I think this is a real effect but is not a mirage			\cite{shah2006policy,few2019loom, hullman2011visualization}	Data loom. Some interesting papers on the topic: Digital Nudging–Influencing Choices by Using Interface Design, Do defaults save lives?, Policy Through Software Defaults (i'm citing that last one, but i'm flexible)	??	4							
Anchoring Effect (checked)	Comprehension	Reading	Initial framings of information tend to guide subsequent judgements. This can cause readers to place undue rhetorical weight on early observations, which may cause them to undervalue or distrust later observations. 					\cite{ritchie2019lie, hullman2011visualization}	Data loom	??	4							
Semmelweis effect	Comprehension			LONG				\cite{valdez2017framework}	MAybe should delete, covers same content as confirmation bias, Data loom	??	4							
Appeal to common belief	Comprehension			LONG				\cite{few2019loom}	Data loom	??	4							
Law of instrument	Comprehension			LONG				\cite{few2019loom}	Data loom, maybe same as default effect	??	4							