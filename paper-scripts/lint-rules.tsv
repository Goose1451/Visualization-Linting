Error	Taxonomy (cause)	Taxonomy (MC)	mirage-error	Hide	MC Top 4	strong? (MC code)	AUDIT NOTES	Lint	implemented	Citations	Notes	Detection Technique	Taxonomy Order	 	Initial Taxonomy zone	Group			LOOKUP	VALUE
Forgotten Population or Missing Dataset (checked)	Curation	Curation	We expect that datasets fully cover or describe phenomena of interest. However, structural, political, and societal biases can result in over- or under-sampling of populations or problems of importance. This mismatch in coverage can hide crucial concerns about the possible scope of our analyses.			3		Not possible	No	\cite{missingdatasets, dignazio2019draft}										
Missing or LINEBREAK Repeated Records (checked)	Curation	Curation, Wrangling	We often assume that we have one and only one entry for each datum. However, errors in data entry or integration can result in missing or repeated values that may result in inaccurate aggregates or groupings (see \figref{fig:misspelling}). TODO WRONG FIG POINTER.		TRUE	1	Metamorphic testing is possible: "remove all copies" could possibly check types	Direct possible	No	\cite{kim2003taxonomy} 		Data, Spec	1	Aggregates might become inaccurate, impeding all comparisons	Totally Invisible	Aggregation issues			Curation	1
Outliers (checked)	Curation	Curation, Wrangling	Many forms of analysis assume data have similar magnitudes and were generated by similar processes. Outliers, whether in the form of erroneous or unexpectedly extreme values, can greatly impact aggregation and discredit the assumptions behind many statistical tests and summaries.		TRUE	1				\cite{kim2003taxonomy} 	Can affect ability to read aggregate visualization accurately	Data, Spec	1	Aggregates might become inaccurate, impeding all comparisons	Totally Invisible	Aggregation issues			Wrangling	2
Dubious Data	Curation			TRUE							Cairo's new book	Data	1		Statistical Malpractice					
Insufficient Data	Curation		Data may be cherry picked, as a non-representative sample, or may not be robust enough to accurately backup the rendered claim in the visualization.	TRUE							Cairo's new book	Data	1		Statistical Malpractice					
Spelling Mistakes (checked)	Curation	Curation, Wrangling	Columns of strings are often interpreted as categorical data for the purposes of aggregation. If interpreted in this way, typos or inconsistent spelling and capitalization can create spurious categories, or remove important data from aggregate queries.		TRUE	2	Metamorphic test: merge all categorical fields within a certain hemming distance, expect that to not produce changes			\cite{wang2019uni}		Data	1							
Uniqueness Constraint Failure	Curation		Marks assumed to represent single values might represent several (which may then be further skewed by aggregates like SUM).	TRUE						\cite{wang2019uni}	assumed singular values may be aggregated. Example: making a line chart of year has data from 1.5 years. Users assumes each mark indicates ONE measurement, when in fact their might be several	Data	1							
Unidentified Functional Dependencies	Curation	Curation	A visualization might show a strong relationship between variables, when in fact that relationship is better explained by 	TRUE			Having trouble with this one. I can't seem to get through it without either a length prose example ("assume customers only received a discount if they sold a widget..."), or by referencing a figure. Given that the mirages here are a subtle, and might be picked up as a superset of simpson's paradox or latent variables or something else, maybe this one gets skipped?			\cite{wang2019uni}	Uni-Detect: A Unified Approach to Automated Error Detection in Tables	Data	1							
Drill-down Bias (checked)	Curation	Wrangling, Reading	We assume that the order in which we investigate our data should not impact our conclusions. However, by filtering on less explanatory or relevant variables first, the full scope of the impact of later variables can be hidden. This results in insights that address only small parts of the data, when they might be true of the larger whole.		TRUE	3	Could conceivable lint if you've got a bunch of filters applied by just applying them in a random order and seeing how fragile the bar height order is? If it's robust you'd expect it to be only when the last filter is applied, no matter the order. Seems contrived, though you could also just do the direct lint in the paper.			\cite{lee2019avoiding}		Data, Spec	1		Statistical Malpractice					
Geopolitical Boundaries in Question (checked)	Curation	Curation	Shifting borders and inconsistent standards of ownership can cause geospatial visualizations to be inconsistent. For instance, statistical measures for the United States change significantly depending on whether protectorates and territories are included, or if overseas departments are excluded when calculating measures for France. This issues are more complex when nationstates disagree on the border and extent of their own territory, which can cause maps to display significantly different data based on who is viewing the data with what software from what location.	LONG			Is french guiana counted as part of france?	Direct	No	\cite{missingdatasets,soeller2016mapwatch}										
Differing Number LINEBREAK of Records by LINEBREAK Group (checked)	Wrangling	Wrangling	Certain summary statistics, including aggregates, are sensitive to sample size. However, the number of records aggregated into a single mark can very dramatically. This mismatch can mask this sensitivity and problematize per-mark comparisons; when combined with differing levels of aggregation, it can result in counter-intuitive results such as Simpson's Paradox.		TRUE	1	Lives in wrangling bc it's a result of the aggregation decision	Direct, MT	Yes	\cite{guo2017you}	A mismatch in row cardinality (world indicators example)	Data, Spec	2	Aggregate may be perceived as having a common cardinality	Totally Invisible	Aggregation issues				
Simpson's Paradox	Wrangling	Wrangling	An observed trends reverses when the aggregation level changes.  Trends observed across groups at one level of aggregation may change or even reverse when the aggregation level changes, due to differing sizes of groups. This can result in counter-intuitive or erroneous insights if 	TRUE			Lots of overlap with the "Differing Numbers of Records by Group" in that we describe both as being where differing group sizes combined with aggregation = badness. Might make sense to merge diff. #s of records with this one?			\cite{guo2017you}		Data, Spec	2	Observed trend reverses when aggregation changes	Totally Invisible	Aggregation issues				
Cherry Picking (checked)	Wrangling	Wrangling, Reading	Filtering and subsetting are meant to be tools to remove irrelevant data, or allow the analyst to focus on a particular area of interest. However, if this filtering is too aggressive, or if the analyst focuses on individual examples rather than the general trend, this cherry-picking can promote erroneous conclusions or biased views of the relationships between variables. Failing to keep the broader dataset in context can also result in the Texas Sharpshooter Fallacy or other forms of HARKing~\cite{cockburn2018hark}.		TRUE	3	Some overlap here with the Drill Down Bias			\cite{few2019loom}	e.g. the chart filters out to only a tiny subset of data where something is true. data loom: law of small numbers (cherry picking, bias sample fallacy)	Data, Spec	2		Totally Invisible					
Outliers Dominate Scale Bounds (checked)	Wrangling	Wrangling, Visualization	Numeric and color scales are often automatically bound to the extent of the data. If there are a few extrema values, this can result in a renormalization in which much of the data is compressed to a narrow output range, destroying the visual signal of potential trends and variability	LONG			Should merge with the other scale issues IMO			\cite{correll2016surprise,kindlmann2014algebraic}	SLIGHTLY UNSURE ABOUT CLASSIFICATION	Data, Spec	2	Real trend is made invisible						
Spurious Correlation	Wrangling	Wrangling	Correlation is not robust to slight changes in the data, which may give the impression of a non-extant correlation.	TRUE							Correlation is not robust to slight changes in the data	Data	2		Statistical Malpractice					
Higher Noise than Effect Size (checked)	Wrangling	Curation, Wrangling	We often has access to only a sample of the data, or noisy estimates of an unknown true value. How the uncertainty in these estimates is communicated, and whether or not the viewer is made aware of the relativel robustness of the effect in the context of this noise, can affect the resulting confidence viewers have in a particular effect.			4				\cite{hofmann2012graphical,hullman2017imagining}		Data	2	Irrelevant conclusions could be made	Statistical Malpractice					
Analyst Degrees of Freedom (checked)	Wrangling	Wrangling	Analysts have a tremendous flexibility in how they analyze data. These ``researcher degrees of freedom''~\cite{gelman2013garden} can create conclusions that are highly idiosyncratic to the choices made by the analyst, or in a malicious sense promote ``p-hacking'' where the analyst searches through the parameter space in order to find the best support for a pre-ordained conclusion. A related issue is the ``multiple comparisons problem'' where the analyst makes \emph{so many} choices that at least one, just by happenstance, is likely to appear significant, even if there is no strong signal in the data.		TRUE	3				\cite{gelman2013garden,pu2018garden,zgraggen2018investigating}	Spurious difference (due to p-hacking, say. or just un-communicated sampling variability)	Data	2	Gives the impression of an non-extant correlation	Statistical Malpractice					
Outliers Combined with Wrong Aggregation Type	Wrangling	Wrangling	Using extremal aggregates (such as min/max) will likely cause misinterpretation of bars as readers tend to assume bars show sums. (I THINK THIS WHAT WITHIN BAR SAYS)	TRUE		4	I'm getting a mismatch here between title and description			\cite{newman2012bar}		Data, Spec, Render	2							
Aggregates Mask Second Order Statistics (checked)	Wrangling	Wrangling	We often assume that the presentation given to us captures the critical details of the data being considered. Unfortunately highly reductive measures, like averages, can mask second order statistics, which often carry critical information about the variance or distribution, which is masked through simple central tendencies. 	LONG						\cite{wall2017warning, few2019loom, matejka2017same, anscombe1973graphs, salimi2018bias}	dinosaurus box plot, anscombe's quartet, variation blindness (the median isn't the message - gould)	Data, Spec, Render	2	Two things may appear to be equal when in fact their distributions are fundamentally different	Totally Invisible	Aggregation issues				
Additional Loom Statistical errors	Wrangling			TRUE						\cite{few2019loom}	data loom: law of small numbers (cherry picking, bias sample fallacy), insensitivity to small sample size, base rate fallacy, hot hand fallacy, appeal to coincidence, regression fallacy, variation blindness (the median isn't the message - gould)		2							
Insensitivity to Small Sample Size	Wrangling	Reading		TRUE			To me this is a meatspace issue; it's not "caused" by the small sample size, it's caused by people not making the appropriate inferences about the effects of sample size. I'll check how the readings in the cite list use this term.			\cite{few2019loom}	data loom									
Hot Hand Fallacy	Wrangling	Reading		TRUE						\cite{few2019loom}	data loom									
Appeal to Coincidence	Wrangling	Reading		TRUE						\cite{few2019loom}	data loom									
Regression Fallacy	Wrangling	Reading		TRUE						\cite{few2019loom}	data loom									
Inappropriate Use of Mean	Wrangling	Wrangling	Mean comparisons between non-normal and normal distribution will be skewed, rendering possibly inaccurate comparisons between groups.	TRUE			Already covered in "Aggregates Mask Second Order Statistics"			\cite{few2019loom}	Data loom (mean is design for normal distributions)	Data, spec	2							
Confusing Imputation (checked)	Wrangling	Wrangling	There are many strategies for dealing with missing or incomplete data, including the imputation of new values. How values are imputed, and then how these imputed values are visualized in the context of the rest of the data, can impact how the data are perceived, in the worst case creating spurious trends or group differences that are merely artifacts of how missing values are handled prior to visualization.		TRUE	2				\cite{song2018s}	"Where's My Data?" 		2							
Sampling Rate Errors (checked)	Wrangling	Curating, Wrangling	Precieved trends in distributions are often subject to the sampling rate at which the underlying data has been curated. This can be problematic as an apparent trend may be an artifact of the sampling rate rather than the data (as is the case visualizations that do not follow the rates suggested by the Nyquist frequency).			3				\cite{kindlmann2014algebraic}			2	Apparent trend will be the aliases rather than the signal						
Data Classes Distinctions Ignored	Wrangling	Wrangling	Multiple distinct data classes presented as the same can cause errors in the inference of trends.	TRUE		4	Sort of fall into Simpson's paradox if we frame this the right way  Yeah, I think our latent variable stuff captures this.			\cite{anand2015automatic}	Automatic Selection of Partitioning Variables for Small Multiple Displays,related to simpson's paradox	Data, spec	2							
Non-sequitur LINEBREAK Visualizations (checked)	Visualization	Visualization	Readers expect graphics that appear to be charts to be a mapping between data and image. Visualizations being used as decoration (in which the marks are not related to data) present non-information that might be mistaken for real information. Even if the data are accurate, additional unjustified annotations could produce misleading impressions, such as decorating uncorrelated data with a spurious line of best fit.		TRUE	1		MT	yes	\cite{correll2017black}										
Banking to 45 Failure	Visualization	Visualization	Not using an appropriate aspect ratio can cause trends to be hallucinated in otherwise trend-free data.	TRUE		5	Falls under other scale manipulation issues 			\cite{heer2006multi}	HEER PAPER. Mirages can be perceptual in nature, but are driven by a decision somewhere in the analytics pipeline. The knob that controls this mirage is charts dimensions	Data, spec, render	3	Trend can appear from flat data or vice-versa						
Misunderstand Area as Quantity (checked)	Visualization	Visualization	The use of area encoded marks assumes readers will be able to visually compare those areas. Area encoded marks are often misunderstood as encoding length which can cause ambiguity about interpretation of magnitude.			4				\cite{pandey2015deceptive, correll2017black}	e.g. “the incredible shrinking doctor”	Spec	3		Visible Only With Effort	Bad Quant Scales				
Non-discriminable Colors (checked)	Visualization	Visualization	The use of color as a data-encoding channel presumes the perceptual discriminability of colors. Poorly chosen color palettes, especially when marks are small or cluttered (cite), can result in ambiguity about which marks belong to which color classes.			3				\cite{szafir2017modeling}		Spec	3	Reader mistakes one group for another	Visible Only With Effort	Bad color scale				
Unconventional Scale Directions (checked)	Visualization		Viewers have certain prior expectations on the direction of scales. For instance, in languages with left-to-right reading orders, time is likewise assumed to move left to right in graphs. Depending on context, dark or opaque colors are perceived as having higher magnitude values than brighter or more transparent colors. Violating these assumptions can cause slower reading times or even the reversal of perceived trends.							\cite{correll2017black,pandey2015deceptive,tversky1991cross,schloss2018mapping}	Readers tend to think of time as flowing in the same direction as their language (CITATION), eg western language speakers tend to think of it as moving from left to right while REST OF EXAMPLE.	Spec, Data, Render	3							
Overplotting (checked)	Visualization		We expect to be able to clearly identify individual marks, and expect that one visual mark corresponds to a single value or aggregated value. Yet overlapping marks can hide internal structures in the distribution or disguise potential data quality issues, as in \figref{fig:opacity-permute}.		TRUE	1		MT	YES	\cite{correll2018looks,mayorga2013splatterplots,micallef2017towards}		Data, Spec, Render	3		Totally Invisible	Rendering Issues				
Singularities (checked)	Visualization	Visualization	In chart types, such as line series or parallel coordinates plots, many data series can converge into a single point in visual space. Without intervention, viewers can have issues discriminating between which series takes which path after such a singularity.	LONG		2		MT		\cite{kindlmann2014algebraic}	parallel coordinates AVD example	Data, Render	3		Totally Invisible	Rendering Issues				
Improper Layering / Overplotting	Visualization	Visualization	Overplotting can cause an non-existent trend to emerge due to the draw order. 	TRUE			AM: Overplotting is it's own thing			\cite{kindlmann2014algebraic}	taxi AVD example	Data, Render	3		Totally Invisible	Rendering Issues				
Latent Variables Missing (checked)	Visualization	Wrangling, Visualization	When communicating information about the relationship between two variables, we assume that we have all relevant data. However, in many cases a latent variable has been excluded from the chart, promoting a spurious or non-causative relationship (for instance, both drowning deaths and ice cream sales are tightly correlated, but are related by a latent variable of external temperature). Even if this variable is present, if the relevant functional dependency is unidentified, the appropriate causal linkage between variables may not be visible in the chart. Similarly, subgroups or subpopulations can exist in datasets that, if not properly separated or identified, can apply universal trends to inappropriate subgroups.			5				\cite{anand2015automatic,wang2019uni}		Spec	3		Totally Invisible					
Wrong/Missing Aggregation (checked)	Visualization	Wrangling	The size of the dataset is often far larger than what can fit in a particular chart. Aggregation at a particular level of detail a common technique to reduce the size of the data. However, the choice of aggregation function can lead to differing conclusions based on the underlying distribution of the data. Furthermore, these statistical summaries may fail to capture important features of distribution. Conversely, when a designer fails to apply an aggregation function (or applies one at too low a level of detail), the overplotting, access visual complexity, or reduced discoverability can likewise hide important patterns in the data.			5				\cite{anscombe1973graphs,matejka2017same}		Spec, Render	3		Totally Invisible					
Flipped Axes (checked)	Visualization	Visualization	There are conventional expectations for the meaning of axis directions (e.g., time as left to right). When a design ignores those expectations, it can result in a perceived inversion of the trend. 	TRUE		2	Error occurs in reading, but "mistake" is in the spec. Superset of line "Unconventional Direction of Time.	direct		\cite{pandey2015deceptive, correll2017black}	Black hat, panday, Variables on Scatter Plots Look More Highly Correlated When the Scales are Increased	Spec	3	Trend understood to be opposite	Visible Only With Effort	Bad Quant Scales				
Scale Extents Larger than Range of the Data	Visualization	Visualization	Differences compressed and visual variability is removed.	TRUE		3	I feel like maybe we just need one giant "scale manipulation" rule rather than these piece-wise ones?			\cite{cleveland1982variables}	Variables on Scatter Plots Look More Highly Correlated When the Scales are Increased	Spec	3		Visible Only With Effort	Bad Quant Scales				
Non-linear Scales	Visualization	Visualization	Can cause readers to inaccurately correlate variables and cluster values.	TRUE		3				\cite{pandey2015deceptive}		Spec	3		Visible Only With Effort	Bad Quant Scales				
Truncated/Expanded Axes	Visualization	Visualization	Where axes begin in a chart control the visual size of group differences, potentially misleading viewers as to the size, significance, or strength of an effect. For instance, beginning the quantitative axis of a bar chart from a value other than 0 can inflate the difference between bars. On the other hand, having quantitative axes that are too broad can artificially magnify the perceived correlation of variables, or suppress variability in a time series chart.	TRUE		2	Covered by the "Mainpulation of Scales"			\cite{pandey2015deceptive, correll2017black, cleveland1982variables, ritchie2019lie, correll2019truncating}	Variables on Scatter Plots Look More Highly Correlated When the Scales are Increased, Black hat, panday	Spec, Data	3	Can cause sorting errors and errors in characterizing distribution						
Colors Binned Unevenly	Visualization	Visualization	Irregular or unintuitive binning may negatively affect interpretation of bin meaning.	TRUE			AM: I'm not actually sure this is a problem?			CITATION?		Spec	3		Visible Only With Effort	Bad color scale				
Base Rate Masquerading as Data (checked)	Visualization	Wrangling, Visualization	Visualizations comparing rates are often assumed to show the relative rate, rather than the absolute rate. Yet, many displays give prominence to these absolute or base rates (such as population in choropleth maps) rather than encoded variable, causing the reader to understand this base rate as the data rate. 			2	Metamorphic test: swap the input data for data that only shows the base rate, if nothing sufficiently changes, then visualization isn't showing the real trend.	MT	No	\cite{correll2016surprise}	Surprise Maps	Spec	3		Visible Only With Effort	Bad color scale				
Inappropriate Semantic Color Scale (checked)	Visualization	Visualization	Colors have different affects and semantic associations depending on context (for instance the cultural context of green being associated with money in the United States). Color encodings in charts that violate these assumotions can result in viewers misinterpreting the data: for instance, a viewer might be confused by a map in which the oceans are colored green, and the land colored blue.			4		Direct / Not possible	No	\cite{lin2013selecting}	Green or blue map regions can lead the reader to believe that those regions posses semantically meaningful trends (forest/ocean respectively). CITATION NEEDED, maybe Selecting Semantically‐Resonant Colors for Data Visualization	Spec?	3			Bad color scale				
Within-the-Bar-Bias (checked)	Visualization	Visualization	The filled in area underneath a bar chart does not communicate any information about likelihood. However, viewers often erroneously presume that values inside the visual area of the bar are liklier or more probable than values outside of this region, leading to erroneous or biased conclusions about uncertainty.			4				\cite{correll2014error,newman2012bar}	Bar graphs depicting averages are perceptually misinterpreted: The within-the-bar bias	Spec	3	Readers misunderstand variability 	Visible Only With Effort	Rhetorical Nudges				
Highlighting/Downplaying Outliers	Visualization	Visualization	Over highlighting outliers can mask important data features, however so can ignoring them.	TRUE		4				CITATION?		Spec	3		Visible Only With Effort	Rhetorical Nudges				
Clipped Outliers (checked)	Visualization	Visualization	Charts are often assumed to show the full extent of their input data. A chosen domain might exclude meaningful outliers, causing some trends in the data to be invisible to the reader.			5	This might be subsumed by cherry picking? Also overlaps with the "Scale Extents Larger than Range of the Data" rule	Direct	No		specified domain removes significant outliers, may be the same as cherry picking	Data, Spec	3							
Continuous Marks for Nominal Quantities (checked)	Visualization	Visualization	Conventionally readers assume lines indicate continuous quantities and bars indicate discrete quantities. Breaking from this convention, for instance using lines for nominal measures, may cause readers to hallucinate non-existent trends based on ordering. 			4				\cite{mcnuttlinting, zacks1999bars}	Eg Line chart across nominal data. Citation VisLint, possibly also http://people.cs.uchicago.edu/~glk/class/datavis/lit/#Zacks-BarsAndLines-1999	Data, Spec	3		Charting malfeasance	Expressiveness mismatches				
Using Ordinal Measures as (Ratio/Interval) Measures	Visualization	Visualization	Related to "area/length mismatches" a mark might be encoded as big/medium/small which readers might then read as quantitative.	TRUE		4				\cite{stevens1946theory, few2019loom}	Stevens, also data loom as "conflating rankings with measure of worth"	Data, spec	3							
V-Hacking	Visualization		Visualization includes arbitrary choices made by the designer that causes reader to hallucinate un-meaningful inferences. The modifiable areal unit problem is an example of this problem.	TRUE			AM: I knocked this one out because we coin the term and we don't describe it. It seems like it would need a more serious description than an entry in a table.			\cite{fotheringham1991modifiable, kindlmann2014algebraic}		Spec, Render	3	Purported insight not robust to minor changes	Charting malfeasance					
Modifiable Areal Unit Problem (checked)	Visualization	Visualization	Spatial aggregates are often assumed as presenting their data without bias, yet they are highly dependent on the shapes of the bins defining those aggregates. This can cause readers to misunderstand the trends present in the data.	LONG		4	Metamorphic testing strategy: count the fraction of number of bins showing each of a collection of data classes (say high/medium/low incidence of cancer), change the bin shape randomly a bunch of time, count again, compare rates.   I keep going back and forth on whether or not this should be in?	Direct, MT	No	\cite{fotheringham1991modifiable, kindlmann2014algebraic}	If you don't like modifiable areal unit being baked into v-hacking....									
Charting Parameter Masking Data Error	Visualization	Visualization	Non-data parameters can mask a critical data errors, such as a histogram binning hiding a missing value.	TRUE		2	Metamorphic test: change the number of bins check for significant changes to the bin character. More concrete: use DTW to compare bar order. KL DIVERGENCE?  There has to be a better, more accurate name for this one  Covered by the default bias imo	MT	No	\cite{correll2018looks}	Over/under smoothed KDE, Over/under binned histogram. Looks good to me	Data, Spec, Render	3		Charting malfeasance					
Poorly Designed Charts	Visualization			TRUE							Cairo's new book	Spec	3		Charting malfeasance					
Concealed LINEBREAK Uncertainty (checked)	Visualization	Visualization, Wrangling	Charts that don't indicate that they contain uncertainty risk giving a false impression as well a possible extreme mistrust of the data if the reader realizes the information hasn't been presented clearly. There is also a tendency to incorrectly assume that data is high quality or complete, even without evidence of this veracity.		TRUE	2	This one also overlaps with "Higher Noise Than Effect Size" but is arguably a more important umbrella problem (in which case it lives in both wrangling and visualizing)..Visualization, Wrangling? (or maybe even Curating?) Issues of not bothering to even measure the uncertainty versus measuring it but not visualizing it			\cite{song2018s, few2019loom, mayrTrust2019, sacha2015role}	Cairo's new book, Slightly different than missing records, following "Where's My Data?" visualizations should represent their missing data in some way. Maybe can point to "The Role of Uncertainty, Awareness, and Trust in Visual Analytics"	Data, Spec, Render	3		Charting malfeasance					
Charts with Misleading Patterns	Visualization			TRUE							Cairo's new book, black hat	Spec, Render	3		Charting malfeasance					
Sole Reliance on Measure of Central Tendency	Visualization	Wrangling	Second order statistics often carry critical information about the variance or distribution, which is masked through simple central tendencies. 	TRUE		5	We've got a lot of "aggregates can be bad" things here. This one also overlaps with "Higher Noise Than Effect Size" and "Concealed Uncertainty"			\cite{wall2017warning, few2019loom, matejka2017same, anscombe1973graphs}	Src: data loom. Could be tested by executing datasarus style data manipulation: keep an invariant the same and rotate the data via optimization	Data, render	3	Second order statistics carry more critical information or variance 						
Manipulation of LINEBREAK Scales (checked)	Visualization	Visualization	The axes and scales of a chart are presumed to straightforwardly represent quantitative information. However, manipulation of these scales (for instance, by flipping them from their commonly assumed directions, truncating or expanding them with respect to the range of the data~\cite{pandey2015deceptive, correll2017black, cleveland1982variables, ritchie2019lie, correll2019truncating}, using non-linear transforms, or employing dual axes~\cite{KindlmannAlgebraicVisPedagogyPDV2016, cairo2015graphics}) can cause viewers to misinterpret the data in a chart, for instance by exaggerating correlation~\cite{cleveland1982variables}, exaggerating effect size~\cite{correll2019truncating,pandey2015deceptive}, or misinterpreting the direction of effects~\cite{pandey2015deceptive}.		TRUE					\cite{cairo2015graphics,correll2017black,correll2019truncating,cleveland1982variables,KindlmannAlgebraicVisPedagogyPDV2016,pandey2015deceptive,ritchie2019lie}										
Trend in Dual Y-Axis Charts are Arbitrary (checked)	Visualization	Visualization	Multiple line series appearing on a common axis are often read as being related through an objective scaling. Yet, when y-axes are superimposed the relative selection of scaling is arbitrary, which can cause readers to misunderstand the magnitudes of relative trends.			3		Direct	No	\cite{KindlmannAlgebraicVisPedagogyPDV2016, cairo2015graphics}	Cairo (poorly designed charts), can also point to that datawrapper blog post									
Uncorrelated Data Decorated with Best Fit Line	Visualization	Visualization	We expect lines of best-fit to accurately represent data trends. Yet, if uncorrelated data is presented alongside a mark conventionally understood to indicate a trend, then a reader may falsely understand those variables as being correlated.  	TRUE		3	This one is fun to talk about and also pretty easy to lint for: just bootstrap all the data and check how the line of best fit moves around. Although if patterned this way, also arguably "Higher Noise Than Effect Size" or "Concealed Uncertainty"				Uncorrelated data decorated with line of best fit. This arises from that line of best fit shown by that psych speaker			Uncareful reader might not investigate if the line of best fit actually matches with anything						
Staircasing	Visualization	Visualization, Wrangling	A trend on a noisy channel may appear to reverse because of the domain selection. MAYBE A SUBSET OF CHERRY PICKING?	TRUE		4	Def. a subset of cherry picking.			IS THIS A KNOWN THING	https://twitter.com/NASAClimate/status/1154503255486955520  setting domain to a small subrange, particularly on a line chart, this might also be a subcase of cherry picking?		3	A trend on a noisy channel may appear to reverse because of the domain selection						
Nominal Choropleth Conflates Color Area with Classed Statistic (checked)	Visualization	Visualization	Choropleth maps color spatial regions according to a theme of interest. However, the size of these spatial regions may not correspond well with the actual trend in the data. For instance, U.S. Presidential election maps colored by county can communicate an incorrect impression of which candidate won the popular vote, as many counties with large area have small populations, and vice versa.			3	Cite the surprise maps work perhaps? Or a cartogram paper; I can think of a couple that might work.			\cite{gastner2005maps,nusrat2016state}										
Overwhelming Visual Complexity (checked)	Visualization	Visualization	We assume that there is a benefit to presenting all of the data in all of its complexity. However, visualizations with too much visual complexity can overwhelm or confuse the viewer and hide important trends, as with graph visualization ``hairballs.''			2	I wonder if there's a higher level mirage here like "overwhelming visual complexity" where the mirage is that you can't determine if a trend is there because there's too much visual noise or adornment. Would capture some data-ink minimalism stuff as well.			\cite{hofmann2012graphical, greadability}										
Reification (checked)	Comprehension	Reading	It can be easier to interpret a chart or map as being a literal view of the real world, rather than to understand that it as abstraction at the end of a causal chain of decision-making. That is, as confusing the \emph{map} with the \emph{territory}. This misunderstanding can lead to falsely placed confidence in measures containing flaws or uncertainty: Drucker~\cite{drucker2012humanistic} claims that reification caused by information visualization results in a situation ``as if all critical thought had been precipitously and completely jettisoned.''	LONG						\cite{drucker2012humanistic}	https://en.wikipedia.org/wiki/Reification_(fallacy)									
Incorrectly Assumed High Quality Data/ Completeness bias	Comprehension	Reading	Trusting untrustworthy data cause readers to make incorrect conclusions about the information presented in a visualization.	TRUE		5	Definitely a different thing, but I feel like this could live as an aside in "Concealed Uncertainty"			\cite{mayrTrust2019, sacha2015role}	The Role of Uncertainty, Awareness, and Trust in Visual Analytics, trust in information visualization	Data	4	Trusting untrustworthy data can lead to missing upstream errors (such as falsey data)	Visible Only With Effort	Data quality errors			Visualization	3
Assumptions of Causality (checked)	Comprehension	Reading	We assume that highly correlated data plotted in the same graph have some important linkage. However, through visual design or arbitrary juxtaposition, viewers can come away with erroneous impressions of relation or causation of unrelated or non-causally linked variables.							\cite{xiong2019illusion, few2019loom}										
Base Rate Bias (checked)	Comprehension	Reading	Readers assume unexpected values in a visualization are emblematic of reliable differences. However, readers may be unaware of relevant base rates: either the relative likelihood of what is seen as a surprising value or the false discovery rate of the entire analytic process.		TRUE	4				\cite{correll2016surprise,pu2018garden, zgraggen2018investigating}	Garden of forking paths, Zerdraggen. Possibly not relevant as we've constrained ourselves to presentational VA.	???	4	False inference from too many iterative comparisons	Statistical Malpractice				Comprehension	4
Inaccessible Charts (checked)	Comprehension	Reading	As charts makers we often assume that our readers are homogeneous groups. Yet, the way that people read charts is heterogeneous and dependent on underlying perceptual abilities and cognitive backgrounds that can be overlooked by the designer. Insufficient mindfullness of these differences can result in miscommunication. For instance, a viewer with color vision deficiency may interpret two colors as identical when the designer intended them to be separate.		TRUE					\cite{lundgard2019Sociotechnical, plaisant2005information}										
Not Accounting for Bias	Comprehension	Reading	Not addressing bias in the visual analytics process can lead analysts towards false conclusions.	TRUE		5	"Biased into not seeing biases" seems like one too many levels of meta for this table.			\cite{wall2017warning}	Ala "bias may occur"	??	4							
Assuming View-from-Nowhere	Comprehension	Reading	The reader might inaccurately trust a visualization that doesn't present its origins.	TRUE		5	I think this can be folded into "Not Accounting for Bias" (although funnily enough it contradicts it slightly since if you assume that you can "account" for bias then you presume the existence of an unbiased central view,...			\cite{dignazio2019draft, d2016feminist}	maybe same as not accounting for bias			Falsely trust visualizations that have a bias						
Causal Errors: Post hoc ergo propter hoc	Comprehension			TRUE						\cite{few2019loom}		??	4							
Causal Errors: Unit Bias	Comprehension			TRUE						\cite{few2019loom}		??	4							
Causal Errors: Outcome Bias	Comprehension			TRUE						\cite{few2019loom}		??	4							
Over-emphasizing Data-ink Minimalism	Comprehension	Visualization	Chart might not actually get read, minimalist charts are easier to ignore full message might get lost	TRUE				Not possible	no	\cite{bateman2010useful}	Data humanism/feminism: extremely minimalist data visualizations aren't memorable (MONSTER CITATION) or as emotionally impactful as illustrative ones (Data fem) . Visual Difficulties also might be of note here	??	4							
Confirmation Bias	Comprehension	Reading	Visualizations of data often lend an objective tone to analysis, however this medium does not prevent readers from projecting their own beliefs onto charts. This may cause readers to see trends that don't exist.	TRUE		3	I wonder if we can compress a bunch of the bias ones together. Something about "Reader Expectations Biasing Comprehension"			\cite{valdez2017framework, few2019loom}	Data loom	??	4							
Availability Heuristic (checked)	Comprehension	Reading, Wrangling	Examples that are easier to recall are perceived as more typical than they actually are. In an visual analytics context, this could be reflected in analysts recalling outlying instances more easily than values that match the trend, or assuming that the data patterns they encounter most frequently (for instance, in the default or home view of their tool) are more common than in they really are in the dataset as a whole.	LONG						\cite{dimara2016accounting,dimara2018task,few2019loom}	Data loom	??	4	Falsely extrapolate meaning from data based on completionist set of data.						
Familiarity Errors: status quo bias	Comprehension			TRUE						\cite{few2019loom}	Data loom	??	4							
Default Effect (checked)	Comprehension		While default settings in visualization systems are often selected to guide users towards best practices, these defaults can have an outsized impact on the resulting design. This influence can result in mirages: for instance, default color palettes can artificially associate unrelated variables; or default histogram settings can hide important data quality issues.				AM: I think this is a real effect but is not a mirage			\cite{correll2018looks,few2019loom, hullman2011visualization,shah2006policy}	Data loom. Some interesting papers on the topic: Digital Nudging–Influencing Choices by Using Interface Design, Do defaults save lives?, Policy Through Software Defaults (i'm citing that last one, but i'm flexible)	??	4							
Anchoring Effect (checked)	Comprehension	Reading	Initial framings of information tend to guide subsequent judgements. This can cause readers to place undue rhetorical weight on early observations, which may cause them to undervalue or distrust later observations. 		TRUE	2				\cite{ritchie2019lie, hullman2011visualization}	Data loom	??	4							
Semmelweis Effect	Comprehension		We assume that readers of charts will dispassionately consume the information they contain. However, new evidence that contradicts tightly held beliefs is often discounted or discarded.	TRUE						\cite{valdez2017framework}	MAybe should delete, covers same content as confirmation bias, Data loom	??	4							
Appeal to Common Belief	Comprehension			TRUE						\cite{few2019loom}	Data loom	??	4							
Law of Instrument	Comprehension			TRUE						\cite{few2019loom}	Data loom, maybe same as default effect	??	4							
Biases in LINEBREAK Interpretation (checked)	Comprehension	Reading	Each viewer arrives to a visualization with their own preconceptions, biases, and epistemic frameworks. If these biases are not carefully considered, various cognitive biases such as the backfire effect or confirmation bias can cause viewers to anchor on only the data (or the reading of the data) that supports their preconceived notions, reject data that does not accord with their views, and generally ignore a more holistic picture of the strength of the evidence.		TRUE	3				\cite{dignazio2019draft, d2016feminist, few2019loom,wall2017warning,valdez2017framework}										